# -*- coding: utf-8 -*-
"""modulo_limpieza.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BoCtRn_YgJqpV0nzu5Wc1HcgI4uPI0xF

# Modulo de limpieza

Autores: Samuel Suarez, Pablo Bright, Juan Pablo Guzman

---

## Importación de librerias y lectura de datos (archivos)
"""

#Importamos todas las librerias que usaremos en el notebook
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from scipy.signal import medfilt, butter, lfilter, savgol_filter
from scipy.signal import find_peaks
import time
import datetime
import ast
import sys

"""Lectura de datos general  (localización y orientación) y corte de incio y finalización de la sesión de entrenamiento"""

#Se reciben los nombres/links de los archivos de location y orientation respectivamente, para su posterior lectura
location = sys.argv[1]
orientation = sys.argv[2]

#Se recibe por parametro los tiempo de inicio y finalización de la sesión. esto con el fin de solo identificar los momentos importantes y no el dataset completo
start_time = pd.Timestamp(sys.argv[3])
end_time = pd.Timestamp(sys.argv[4])

#Se cargan los dataset de location y orientation
dataLoc = pd.read_csv(location, sep=",", header='infer')
dataOr = pd.read_csv(orientation, sep=",", header='infer')

#Se convierten los datos de tiempo dentro de los dataset a formato datetime, debido a que llegan en formato timestamp que no es preferible para el manejo
dataLoc['time'] = pd.to_datetime(dataLoc['time'], unit='ns')
dataOr['time'] = pd.to_datetime(dataOr['time'], unit='ns')

#Eliminamos las columnas que no se utilizaran del dataset de orientación
dataOr2 = dataOr.drop(columns=['qx','qy','qz','qw'], axis=1)

#Recortamos el dataset de orientación dados los tiempos que se pasaron por parametro
dataOr3 = dataOr2[(dataOr2['time'].values >= start_time) & (dataOr2['time'].values <= end_time)]
dataOr3.reset_index(inplace = True)

#Recortamos y eliminamos las columnas que nos sobran en Location
dataLoc2 = dataLoc.drop(columns=['altitude', 'speedAccuracy', 'bearingAccuracy', 'altitudeAboveMeanSeaLevel', 'bearing', 'horizontalAccuracy', 'verticalAccuracy'], axis=1)

#Recortamos el dataset de location dados los tiempos que se pasaron por parametro
dataLoc3 = dataLoc2[(dataLoc2['time'].values >= start_time) & (dataLoc2['time'].values <= end_time)]
dataLoc3.reset_index(inplace = True)

"""## Filtro y ajuste de señales

Se hace una normalización de los datos recibidos, escalando los datos de location al tamaño de los demas conjuntos de dato.
"""

def interpolate_linear(array_parameter,data):

  """
  Ajuste de un arreglo de datos al tamaño del dataframe recibido por parametro
  # Parametros:
    - array_parameter: list
    Arreglo a expandir, con la condición de que los valores dentro del arreglo deben de ser
    de tipo numerico
    - data: pd.DataFrame
    Dataframe del que se tomara el tamaño para generar el arreglo expandido
  # Salida:
    - out: list
    Arreglo expandido con el tamaño del dataframe pasado por parametro

  """

  specific_values = array_parameter
  #Definir rango
  print( len(specific_values), data.shape[0], specific_values.iloc[-1])

  start_value = specific_values.iloc[0]

  end_value = specific_values.iloc[-1]

  #Arreglo para la respuesta
  lineal = np.array([])

  #Generar datos del arreglo
  for i in range(len(specific_values)):
      if i == 0:
        interval_points = np.linspace(start_value, specific_values.iloc[i], num=data.shape[0] // len(specific_values))
      else:
        interval_points = np.linspace(specific_values.iloc[i - 1], specific_values.iloc[i], num=data.shape[0] // len(specific_values))

      lineal = np.concatenate((lineal, interval_points))

  #Añadir intervalo final
  interval_points = np.linspace(specific_values.iloc[-1], end_value, num=data.shape[0]-len(lineal))
  lineal = np.concatenate((lineal, interval_points))
  return lineal

def apply_median_filter(data, columns, window_size=3):
    """
    aplicación de filtro *median* a las señales indicadas por parametro, especializado en señales de frecuencia media
    # Parametros:
    - data: pd.DataFrame
    Objeto tipo Dataframe al cual se le aplicara el filtro
    - columns: list
    Lista de columnas dentro del dataframe *data* a las que se les aplicara el filtro
    -window_size: int, default = 3
    tamaño del filtro
    # Salida:
      - out: pd.DataFrame
    """
    filtered_data = data.copy()
    for col in columns:
        filtered_data[col] = medfilt(data[col], kernel_size=window_size)
    return filtered_data

def apply_low_pass_filter(data, columns, cutoff_freq, fs=10):
    """
    Aplicación de filtro low pass para las señales indicandas por parametro, especializado en señales de baja frecuencia
    # Parametros:
    - data: pd.DataFrame
    Objeto tipo Dataframe al cual se le aplicara el filtro
    - columns: list
    Lista de columnas dentro del dataframe *data* a las que se les aplicara el filtro
    -cuttoff_freq: int

    -fs: int

    # Salida:
      - out: pd.DataFrame
    """
    filtered_data = data.copy()
    nyquist_freq = 0.5 * fs
    normal_cutoff = cutoff_freq / nyquist_freq
    b, a = butter(1, normal_cutoff, btype='low', analog=False)

    for col in columns:
        filtered_data[col] = lfilter(b, a, data[col])
    return filtered_data

#Lectura de datos de viento pasados por parametro en modo de lista i.e: '[1,2,4,5]', despues convertidos a objeto
wind = pd.DataFrame({
      'speed': ast.literal_eval(sys.argv[5]),
      #'speed': [4,5,3,4.83,3.9],
      'grades': ast.literal_eval(sys.argv[6])
      #'grades':[25,20,25,5,345]
})

#Interpolación de los datos de viento para ajustar el tamaño de la lista al tamaño del dataset
lineal = interpolate_linear( wind['speed'] , dataOr3)
angles = interpolate_linear( wind['grades'] , dataOr3)

#Se crea un nuevo objeto dataframe con los datos de velocidad interpolados, junto con los datos de velocidad y anuglo de viento.
dataLoc4 = pd.DataFrame({
    'speed': interpolate_linear(dataLoc3['speed'], dataOr3),
    'time': dataOr3['time'],
    'wind_speed': lineal,
    'wind_angles': angles
    })

def adjust_yaw(data):
    """
    Ajuste de la columna *yaw* del dataframe de orientación, con el fin de mantener datos positivos
    # Parametros:
      - data: pd.DataFrame
      Dataframe al que se sumara 2π a la columna *yaw* a los datos que sean negativos
    # Salida:
      - out: pd.core.series
      lista con los valores de *yaw* ajustados
    """
    # Copy the data to avoid modifying the original DataFrame
    adjusted_data = data.copy()

    # Locate negative values in the 'yaw' column and add 2π
    adjusted_data['yaw'] = np.where(adjusted_data['yaw'] < 0, adjusted_data['yaw'] + 2 * np.pi, adjusted_data['yaw'])

    return adjusted_data

#Se ajustan lo valores de la guiñada para mantener todos lo valores en un eje positivo
dataOr3 = adjust_yaw(dataOr3)

#Se aplican los filtros low pass y median a los valores de las columnas de yaw, roll y pitch. Se aplican ambos filtros puesto que las frecuencias presentadas dentro del dataframe tienden a se de baja/media intensidad, con el fin de suavizar el ruido presentado
dataOr_F = apply_median_filter(apply_low_pass_filter(dataOr3, columns=['yaw', 'roll', 'pitch'],cutoff_freq=1,fs = 10), columns=['yaw', 'roll', 'pitch'], window_size=3)

#Se aplica el filtro median a los valores de velocidad del dataframe location, puesto que mayoritariamente presenta frecuencias de media intensidad que deben ser ajustadas
dataLoc_F = apply_median_filter(dataLoc4, columns=['speed'], window_size=3)

"""Utilizamos un filtro doble, aplicando low pass y median, de esta manera podemos disminuir el ruido en dos rangos diferentes de frecuencias, pero manteniendo los movimientos y sensibilidad de los datos originales

## Detectar los virajes
"""

def keep_middle_value_of_true_groups(data, condition_column):
    """
    Mantener solo un valor 'True' en grupos consecutivos verdaderos de una columna

   # Parametros:
      - data: pd.DataFrame
      Dataframe al que se le manipulara una columna condición
      - condition_column: str
      Columna de data a la cual se le quiere guardar solamente un dato 'True' por grupo

    # Salida:
      - out: pd.DataFrame
      DataFrame con la columna sin grupos consecutivos 'True' pero valores sueltos
    """
    last_was_true = False
    for index, row in data.iterrows():
        if row[condition_column]:
            if last_was_true:
                data.at[index, condition_column] = False
            last_was_true = True
        else:
            last_was_true = False

    for index, row in data.iterrows():
      if row[condition_column]:
        data.at[index, condition_column] = False
        break

    return data

def detect_constant(data, column, ran, window = 200):
    """
    Detección de momentos constantes a lo largo de una columna especifica de datos, siendo 0 constante y 1 no constante
    # Parametros:
      - data: pd.DataFrame
      Objeto tipo Dataframe al cual se le aplicara el filtro
      - column: list
      Lista de columnas dentro del dataframe *data* a las que se les aplicara el filtro
      - ran: int
      rango de altura de tolerancia para la detección de momento no constantes
      - window: int, default = 200
      cantidad de datos con los que compara al momento de buscar datos constantes

    # Salida:
      - out: pd.core.series
    """
    window_movement = data[column]
    rolling_mad = window_movement.rolling(window=window).apply(lambda x: np.abs(x - x.mean()).mean(), raw=True)
    change_detected = (rolling_mad > ran).astype(int)
    change_detected = change_detected.fillna(0).astype(int)
    return change_detected

# Ajusta tolerancia acorde a la sensibilidad para la detección de cambios
num_samples_behind = 400  # ajuste de valores para la sensibilidad
threshold = 0.9  # ajuste de este valor correspondiente al dataframe utilizado

# Diference with value behind
dataOr_F['diff_behind'] = dataOr_F['yaw'].diff(periods = num_samples_behind)

# Mark in the dataset if the differemce is above the threshold
dataOr_F['change_detected'] = abs(dataOr_F['diff_behind']) > threshold
dataOr_F = keep_middle_value_of_true_groups(dataOr_F, 'change_detected')
dataLoc_F['change_detected'] = dataOr_F['change_detected']

dataOr_F['constant'] = detect_constant(dataOr_F,'yaw', ran = 0.1, window= 200)

"""## Crear nuevos datasets para cada maniobra"""

def create_datasets(df):
    """
    Obtención de tiempos de giro en cada viraje por separado
    # Parametros:
      - data: pd.DataFrame
      Objeto tipo Dataframe
      - max_peaks: list -> int
      Lista de indices de valor maximo de cambio
      - min_peaks: list -> int
      Lista de indices de valores minimos
    # Salida:
      - out: pd.DataFrame
    """
    datasets = []
    for i in range(len(df)):
        if df.loc[i, 'change_detected']:
            start_index = max(0, i - 600)
            end_index = min(len(df), i + 601)
            data = df.iloc[start_index:end_index]
            datasets.append(data)

    return datasets

def reset_index_allTacks(dfs):
  """
     Reiniciar los index de cada dataframe de una lista
     # Parametros:
       - dfs: list
       Lista de DataFrames
     # Salida:
       - out: list
     """
  datasets = []
  for i in range(len(dfs)):
    data = dfs[i].reset_index()
    datasets.append(data)

  return datasets

#Se cortan y reinician los dataframes de orientación y el de localización usando los metodos correspondiente
dataTO = create_datasets(dataOr_F)
dataTO = reset_index_allTacks(dataTO)

dataTL = create_datasets(dataLoc_F)
dataTL = reset_index_allTacks(dataTL)

pd.DataFrame(dataTO[0]).drop(['level_0', 'index'], axis = 1)

#Obtención de tiempos de giro de la guiñada o *yaw*
duration_yaw = []
for i in range(len(dataTO)):
  last_was_true = False
  for index, row in dataTO[i].iterrows():
      if row['constant'] == 1 :
          if last_was_true:
              time_final=dataTO[i].at[index,'time']
          else:
              time_inicial=dataTO[i].at[index,'time']
          last_was_true = True
      else:
          last_was_true = False
  duration_yaw.append((time_final - time_inicial).total_seconds())

#Extracción de datos a modo de matriz de los dataframe, para un posterior manejo
matrix_speed = list(map(lambda x: dataTL[x]['speed'], range(len(dataTL))))
matrix_yaw = list(map(lambda x: dataTO[x]['yaw'], range(len(dataTO))))
matrix_roll = list(map(lambda x: dataTO[x]['roll'], range(len(dataTO))))
matrix_constant = list(map(lambda x: dataTO[x]['constant'], range(len(dataTO))))
matrix_time = list(map(lambda x: dataTO[x]['time'], range(len(dataTO))))

def matrix_to_text(matrix):
  """
    Conversion de elementos de una matriz a tipo String
    # Parametros:
      - matrix: list
      Objeto tipo matriz que contenga elementos diferentes a tipo string
    # Salida:
      - out: list
      Matriz con los datos convertidos a tipo String
  """
  comma = ', '
  text_result = []
  for i in matrix:
    result = comma.join(str(item) for item in i)
    text_result.append(result)
  return text_result

matrix_speed_text = matrix_to_text(matrix_speed)
matrix_yaw_text = matrix_to_text(matrix_yaw)
matrix_roll_text = matrix_to_text(matrix_roll)
matrix_constant_text = matrix_to_text(matrix_constant)
matrix_time_text = matrix_to_text(matrix_time)

#Obtención de datos de amplitud del giro y de la guiñada respectivamente, a partir de las matrices de datos previamente creadas
amplitude_roll = list(map(lambda x : matrix_roll[x].max() - matrix_roll[x].min() , range(len(matrix_roll))))
amplitude_yaw = list(map(lambda x : matrix_yaw[x].max() - matrix_yaw[x].min() , range(len(matrix_yaw))))

#Extraccipon de datos promedio de viento de cada maniobra a partir de los dataframe de localización
wind_speed = list(map(lambda x: (dataTL[x]['wind_speed'].mean().astype(float)) if dataTL[x]['wind_speed'].any() == None else (dataTL[x]['wind_speed'].astype(float)), range(len(dataTL))))
wind_angles = list(map(lambda x: (dataTL[x]['wind_angles'].mean().astype(float)) if dataTL[x]['wind_angles'].any() == None else (dataTL[x]['wind_angles'].astype(float)), range(len(dataTL))))

#Exporte de los datos a formato csv
total_dataframe = pd.DataFrame({
    'min_speed': list(map(lambda x: x.min(), matrix_speed)),
    'max_speed': list(map(lambda x: x.max(), matrix_speed)),
    'first_speed': list(map(lambda x: x.iloc[0], matrix_speed)),
    'last_speed': list(map(lambda x: x.iloc[-1], matrix_speed)),
    'mean_speed': list(map(lambda x: x.mean(), matrix_speed)),
    'first_time': list(map(lambda x: x['time'][0], dataTO)),
    'last_time':list(map(lambda x: x['time'][len(x)-1], dataTO)),
    'duration': duration_yaw,
    'amplitude_yaw': amplitude_yaw,
    'amplitude_roll': amplitude_roll,
    'wind_speed': list(map(lambda x: x.mean(), wind_speed)),
    'wind_angles':list(map(lambda x: x.mean(), wind_angles))
})
total_dataframe.to_csv(sys.argv[-1], index=False, sep = ',')

#Exporte de datos de localización (latitude, longitude y tiempo) a formato csv
dataLoc3[['latitude', 'longitude','time']].to_csv('tracker.csv', index = False, sep = ',')